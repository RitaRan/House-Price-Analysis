---
title: "project.Rmd"
author: "Yijun Jiang"
date: "4/21/2017"
output: html_document
---
### Read in Training Data
```{r}
library(MASS)
library(dplyr)
```

To get started read in the training data:
```{r read-data}
load("ames_train.Rdata")
```

The `Neighborhood` variable, typically of little interest other than to model the location effect, may be of more relevance when used with the [map](http://www.amstat.org/publications/jse/v19n3/decock/AmesResidential.pdf).

We are restricting attention to just the "normal sales" condition.

## Part I: Simple Model

In the first model you are allowed only limited manipulations of the original data set to predict the sales price `price`. You are allowed to take power transformations of the original variables [square roots, logs, inverses, squares, etc.] but you are NOT allowed to create interaction variables. This means that a variable may only be used once in an equation [if you use $ x^2$ don’t use $x$]. Additionally, you may eliminate any data points you deem unfit. This model should have a minimum r-square of 73% (in the original units) and contain at least 6 variables but fewer than 20.   

1. Clean Data

* Some variables with a lot of NAs are categorical variables. After checking the data, we found the reason for having so many NAs is because the properties do have the corresponding features. In order to keep as much information as possible, we change those NAs as new levels. For example, NAs in `Alley` are recoded as "No alley access". The variables that are dealt with this way include `Bsmt.Qual`, `Bsmt.Cond`, `BsmtFin.Type.1`, `BsmtFin.Type.2`, `Bsmt.Exposure`, `Bsmt.Full.Bath`, `Bsmt.Half.Bath`, `Fireplace.Qu`, `Garage.Type`, `Garage.Finish`, `Garage.Qual`, `Garage.Cond`, `Fence`, `Misc.Feature`, `Mas.Vnr.Type`, `Mas.Vnr.Area`, ``

* The second issue we found in the data is that new levels are identified in the test data, which causes error messages when making predictions. After using `table()` to check the new levels, we found the new levels only contain one data point, so we decided to classify the the new level to its closest class. For example, `Kitchen.Qual` contains 1 "Po"(poor) in the test data which is a new level, so we reclassify this data point as "Fa"(fair) which is its closest class. The variables that are dealt with this way include `Kitchen.Qual`, `Heating.QC`, `Electrical`, `Condition.2`, `Neighborhood`.

* The third issue we found is that `Lot.Frontage` and `Garage.Yr.Blt` are two continuous variables with a lot of NAs. We are not able to create a new level for the NAs as what we did to the categorical variables. After checking the codebook, we found `Lot.Fontage` might not be useful in predicting the price, which is also proved to be unimportant when we try to fit the boosting model, so we simply droped this variable.

* Lastly, we created a few new categorical variables for interaction.

2. Clean Outliers

* Based on the ordered boxplots of `price` vs. `Neighborhood`(showed below), we found the two most expensive neighborhoods "NridgHt" and "NoRidge" have four properties with extremely high prices(>$580,000). Since they are far away from the main price cluster, we decided to treat them as outliers and remove them. We also check the other neighborhoods and found that the neighborhood "Gilbert" and "NAmes" also have prices extremely high. Those prices are also removed.

```{r}
# price v.s. neighborhood
ggplot(ames_train, aes(x=reorder(Neighborhood, price, FUN=median), y=price))+
  theme_bw()+
  theme(axis.text.x=element_text(angle=45, hjust=1))+
  geom_boxplot()+
  xlab('')+
  ylab('Price')+
  ggtitle("Figure 1. Price by Neighborhood")
```

3. Transformations of the Data and Fit Model

* Transforamtion of response variable `price`:
We first fitted a simplest model called `simple_model` to identify possible transformations of response variable `price`. The diagnostic plots show below indicate a non-constant variance of the residuals, which means a transformation is needed for `price`. With the help of `boxcox()` function and the plot produced below, we found `price` needs a log transformation. 

* Model build and model selection:
We first putted in a few variables that are intuitively important as out base model and kept all the variables put in significant. The variables we chose include `TotalSq`, `Year.Built`, `Garage.Area`, `Overall.Qual`, `Kitchen.Qual`, `Garage.Cond`, etc. Based on this base model, forward selection was used to select more variables that can be included in our model and improve the prediction accuracy. Finally we end up with a model with 20 variables.

* Further improvement:
What we did for further imporvement is plotting individual price vs. the selected features. Log transformation is used on `Lot.Area`. We also double checked the boxcox plot on the updataed model. `price`^0.25 was used to replace the log transformation. We finally end up with a model with a rmse 15453.41.

```{r}
simple_model = lm(price ~ TotalSq, data = ames_train)
plot(simple_model)
boxcox(simple_model)
```

The full R code and analysis is shown below.

```{r}
# clean data
clean_data = function(xdata){
xdata %>%
    mutate(# replace NAs with new levels
           Alley = as.factor(ifelse(is.na(as.character(Alley)), 
                                    "No alley access", as.character(Alley))),
           Bsmt.Qual = as.factor(ifelse(as.character(Bsmt.Qual)=="Po", 
                                           "Fa", as.character(Bsmt.Qual))),
           Bsmt.Qual = as.factor(ifelse(is.na(as.character(Bsmt.Qual)), 
                                           "No Basement", as.character(Bsmt.Qual))),
           Bsmt.Cond = as.factor(ifelse(is.na(as.character(Bsmt.Cond)), 
                                           "No Basement", as.character(Bsmt.Cond))),
           BsmtFin.Type.1 = as.factor(ifelse(is.na(as.character(BsmtFin.Type.1)), 
                                           "No Basement", as.character(BsmtFin.Type.1))),
           BsmtFin.Type.2 = as.factor(ifelse(is.na(as.character(BsmtFin.Type.2)), 
                                           "No Basement", as.character(BsmtFin.Type.2))),
           Bsmt.Exposure = as.factor(ifelse(is.na(as.character(Bsmt.Exposure))|
                                              as.character(Bsmt.Exposure) == "", 
                                           "No Basement", as.character(Bsmt.Exposure))),
           Bsmt.Unf.Rate.SF = ifelse(Total.Bsmt.SF!=0, Bsmt.Unf.SF/Total.Bsmt.SF, 0),
           Bsmt.Full.Bath = ifelse(is.na(Bsmt.Full.Bath),0,Bsmt.Full.Bath),
           Bsmt.Half.Bath = ifelse(is.na(Bsmt.Half.Bath),0,Bsmt.Half.Bath),
           Fireplace.Qu = as.factor(ifelse(is.na(as.character(Fireplace.Qu)), 
                                           "No Fireplace", as.character(Fireplace.Qu))),
           Garage.Type = as.factor(ifelse(is.na(as.character(Garage.Type)),
                                           "No Garage", as.character(Garage.Type))),
           Garage.Finish = as.factor(ifelse(is.na(as.character(Garage.Finish))|
                                              as.character(Garage.Finish) == "",
                                           "No Garage", as.character(Garage.Finish))),
           Garage.Qual = as.factor(ifelse(as.character(Garage.Qual)=="Ex", 
                                          "Gd", as.character(Garage.Qual))),
           Garage.Qual = as.factor(ifelse(is.na(as.character(Garage.Qual)),
                                           "No Garage", as.character(Garage.Qual))),
           Garage.Cond = as.factor(ifelse(as.character(Garage.Cond)=="Ex", 
                                          "Gd", as.character(Garage.Cond))),
           Garage.Cond = as.factor(ifelse(is.na(as.character(Garage.Cond))|as.character(Garage.Cond)=="Po",
                                           "No Garage", as.character(Garage.Cond))),
           # deal with new level issue in test data
           Fence = as.factor(ifelse(is.na(as.character(Fence)),
                                           "No Fence", as.character(Fence))),
           Misc.Feature = as.factor(ifelse(is.na(as.character(Misc.Feature)),
                                           "None", as.character(Misc.Feature))),
           Mas.Vnr.Type = as.factor(ifelse(as.character(Mas.Vnr.Type) == "",
                                           "None", as.character(Mas.Vnr.Type))),
           Mas.Vnr.Area = ifelse(is.na(Mas.Vnr.Area),0,Mas.Vnr.Area),
           Kitchen.Qual = as.factor(ifelse(as.character(Kitchen.Qual)=="Po", 
                                           "Fa", as.character(Kitchen.Qual))),
           Heating.QC = as.factor(ifelse(as.character(Heating.QC)=="Po", 
                                         "Fa", as.character(Heating.QC))),
           Electrical = as.factor(ifelse(as.character(Electrical) == "", 
                                         "SBrkr", as.character(Electrical))),
           Condition.2 = as.factor(ifelse(as.character(Condition.2) %in% c("Artery","RRAn","RRAe"),
                                          "Feedr", as.character(Condition.2))),
           Neighborhood = as.factor(ifelse(as.character(Neighborhood)=="Blueste",
                                          "NPkVill", as.character(Neighborhood))),
           # create new variables
           Enclosed.Porch.is = as.factor(ifelse(Enclosed.Porch==0,"N","Y")),
           Pool.Area = as.factor(ifelse(Pool.Area==0,"N", "Y")),
           Garage.Yr.Blt = ifelse(is.na(Garage.Yr.Blt), Year.Built-2, Garage.Yr.Blt)
          )%>%
    dplyr::select(-c(Lot.Frontage,Pool.QC,Pool.Area))
}

# remove outliers
ames_train = clean_data(ames_train)
ames_train = ames_train[ames_train$price<580000,-1]
remove_idx1 = c(1:nrow(ames_train))[ames_train$Neighborhood %in%c("Gilbert")&ames_train$price>350000]
remove_idx2 = c(1:nrow(ames_train))[ames_train$Neighborhood %in%c("NAmes")&ames_train$price>300000]
remove_idx3 = c(1:nrow(ames_train))[ames_train$Neighborhood %in%c("Landmrk","GrnHill")]
ames_train = ames_train[-c(remove_idx1, remove_idx2, remove_idx3),]

# fit model
model1 = lm(price^(0.25) ~ area + Year.Built + Year.Remod.Add + Garage.Area + Overall.Qual +  log(Lot.Area) + BsmtFin.SF.1 + Overall.Cond + Total.Bsmt.SF + Central.Air + Bsmt.Full.Bath + Screen.Porch + Kitchen.Qual + Exter.Qual + Bldg.Type + Bsmt.Qual + Enclosed.Porch + Garage.Cond + Neighborhood + Heating.QC, data=ames_train)
summary(model1)
plot(model1)
```

### Model Evaluation on Test Data
Create predicted values for price using your model using the testing data

```{r read-test-data}
load("ames_test.Rdata")
ames_test = clean_data(ames_test)
```

```{r predict-model1, echo=FALSE}
Yhat = predict(model1, newdata=ames_test, interval = "pred")
Yhat = Yhat^4
```

You should save your predictions in a dataframe with columns for `PID`  (property identifier), `fit`, predicted values on the test data, and where possible `lwr` and `upr`, lower and upper 95% interval estimates for predicting `price`. 

```{r}
# name dataframe as predictions! DO NOT CHANGE
predictions = as.data.frame(Yhat)
predictions$PID = ames_test$PID
save(predictions, file="predict.Rdata")
```

Your models will be evaluated on the following criteria on the test data: 

* Bias:  Average (Yhat-Y)  positive values indicate the model tends to overestimate price (on average) while negative values indicate the model tends to underestimate price.

* Maximum Deviation:  Max |Y-Yhat| -  identifies the worst prediction  made in the validation data set.

* Mean Absolute Deviation:  Average |Y-Yhat| - the average error (regardless of sign).

* Root Mean Square Error: Sqrt Average (Y-Yhat)^2

* Coverage:  Average( lwr < Y < upr) 

In order to have a passing wercker badge, your file for predictions needs to be the same length as the test data, with three columns:  fitted values, lower CI and upper CI values in that order with names, fit, lwr, and upr respectively.  

You will be able to see your scores on the score board (coming soon!).  They will be initialized by a predction based on the mean in the training data.

_Model Check_ - Test your prediction on the first observation in the training and test data set to make sure that the model gives a reasonable answer and include this in a supplement of your report. This should be done BY HAND using a calculator (this means use the raw data from the original dataset and manually calculate all transformations and interactions with your calculator)! Models that do not give reasonable answers will be given a minimum 2 letter grade reduction. Also be careful as you cannot use certain transformations [log or inverse x] if a variable has values of 0.